"""
ãƒã‚¤ã‚¯éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’é †åºåˆ¶å¾¡ã—ãªãŒã‚‰Whisper APIã§æ–‡å­—èµ·ã“ã—ã™ã‚‹ãŸã‚ã®ã‚­ãƒ¥ãƒ¼ç®¡ç†
"""

import asyncio
import json
import logging
import re
import os
from dataclasses import dataclass
from typing import Awaitable, Callable, Dict, List, Optional

from session_manager import SessionManager
from whisper_client import whisper_client

logger = logging.getLogger(__name__)

# Constants
HOTWORDS_FILE = "backend/hotwords.json"
BASE_PROMPT = "ã“ã‚Œã¯æ—¥æœ¬èªã®ä¼šè©±ã§ã™ã€‚ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚"
AIZUCHI_PATTERN = r"^(ã¯ã„|ãˆãˆ|ã†ã‚“|ã‚|ã‚ã‚|ãªã‚‹ã»ã©|ãã†ã§ã™ã­|ã§ã™ã­|ãªã‚“ã‹|ã¾|ã¾ã|ã‚ã®|ãã®|ãˆã£ã¨)$"


@dataclass
class AudioChunk:
    """ã‚­ãƒ¥ãƒ¼ã«ç©ã‚€éŸ³å£°ãƒãƒ£ãƒ³ã‚¯"""
    base64_data: str
    mime_type: str
    speaker_id: str
    speaker_name: str
    retries: int = 0
    max_retries: int = 3

    def backoff_delay(self, base_delay: float = 1.0) -> float:
        """æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§å¾…æ©Ÿæ™‚é–“ã‚’è¿”ã™"""
        return base_delay * (2 ** max(0, self.retries - 1))


class TranscriptionManager:
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«éåŒæœŸã‚­ãƒ¥ãƒ¼ã‚’æŒã¡ã€éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’é †ç•ªã«å‡¦ç†ã™ã‚‹
    """

    def __init__(
        self,
        session_manager: SessionManager,
        broadcaster: Callable[[str, dict], Awaitable[None]],
        max_queue_size: int = 30,
        concurrency: int = 1,
        on_transcription_appended: Optional[Callable[[str], Awaitable[None]]] = None
    ):
        self.session_manager = session_manager
        self.broadcast = broadcaster
        self.max_queue_size = max_queue_size
        self.concurrency = concurrency
        self.on_transcription_appended = on_transcription_appended

        self.queues: Dict[str, asyncio.Queue[AudioChunk]] = {}
        self.tasks: Dict[str, list[asyncio.Task]] = {}
        self.lock = asyncio.Lock()
        self.session_locks: Dict[str, asyncio.Lock] = {}  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®ãƒ­ãƒƒã‚¯
        self._recent_texts: Dict[str, list[str]] = {}
        self._last_total_text: Dict[str, str] = {}
        self._last_sent_text: Dict[str, str] = {}
        
        self.hotwords = self._load_hotwords()

    def _load_hotwords(self) -> str:
        """hotwords.json ã‹ã‚‰ç”¨èªã‚’èª­ã¿è¾¼ã¿ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã«ã™ã‚‹"""
        if not os.path.exists(HOTWORDS_FILE):
            # Try looking in current directory if backend/ prefix fails (e.g. running from backend dir)
            if os.path.exists("hotwords.json"):
                path = "hotwords.json"
            else:
                logger.warning("âš ï¸ hotwords.json not found")
                return ""
        else:
            path = HOTWORDS_FILE

        try:
            with open(path, "r", encoding="utf-8") as f:
                words = json.load(f)
                if isinstance(words, list):
                    return ", ".join(words)
        except Exception as e:
            logger.error(f"Failed to load hotwords: {e}")
        return ""

    def _construct_prompt(self, session_id: str) -> str:
        """
        Whisper APIã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        Base Prompt + Hotwords + Recent Context
        """
        prompt_parts = [BASE_PROMPT]
        
        if self.hotwords:
            prompt_parts.append(f"ç”¨èª: {self.hotwords}")

        # ç›´è¿‘ã®ä¼šè©± (æœ€å¤§3ä»¶) ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿½åŠ 
        recents = self._recent_texts.get(session_id, [])
        if recents:
            last_sent = self._last_sent_text.get(session_id)
            if last_sent:
                prompt_parts.append(f"ç›´å‰ã®ä¼šè©±: {last_sent}")

        full_prompt = " ".join(prompt_parts)
        return full_prompt[:200]  # tokenæ•°ã§ã¯ãªã„ãŒå®‰å…¨ç­–

    def _filter_transcription(self, text: str) -> Optional[str]:
        """
        æ–‡å­—èµ·ã“ã—çµæœã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        - ç›¸æ§Œ (Aizuchi) ã®é™¤å»
        - ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®é™¤å»
        - Prompt Leakage (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãã®ã‚‚ã®ãŒå‡ºåŠ›ã•ã‚Œã‚‹) ã®é™¤å»
        """
        if not text:
            return None
        
        cleaned = text.strip()
        
        # 0. Prompt Leakage Check
        if cleaned == BASE_PROMPT:
             logger.debug(f"ğŸ§¹ Filtered prompt leakage: {cleaned}")
             return None

        # 1. ç›¸æ§Œãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ (çŸ­ã„å˜ç™ºã®ç›¸æ§Œã®ã¿é™¤å»)
        if re.match(AIZUCHI_PATTERN, cleaned):
            logger.debug(f"ğŸ§¹ Filtered aizuchi: {cleaned}")
            return None

        # 2. ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ (ç¹°ã‚Šè¿”ã—)
        if len(cleaned) > 5 and len(set(cleaned)) == 1:
             logger.debug(f"ğŸ§¹ Filtered distinct char fail: {cleaned}")
             return None
             
        mid = len(cleaned) // 2
        if len(cleaned) > 10 and cleaned[:mid] == cleaned[mid:]:
             logger.debug(f"ğŸ§¹ Filtered loop: {cleaned}")
             return None

        # ã€Œã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€ãªã©ã®Whisperç‰¹æœ‰ã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³
        if "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ" in cleaned or "ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²" in cleaned:
             logger.debug(f"ğŸ§¹ Filtered youtube hallucination: {cleaned}")
             return None

        return cleaned

    @staticmethod
    def _normalize_text(text: str) -> str:
        no_ws = re.sub(r'\s+', '', (text or ''))
        return no_ws.strip().lower()

    async def enqueue_audio_chunk(
        self,
        session_id: str,
        base64_data: str,
        mime_type: str,
        speaker_id: str,
        speaker_name: str
    ) -> None:
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚­ãƒ¥ãƒ¼ã¸æŠ•å…¥"""
        if not whisper_client.enabled:
            logger.debug("Whisper client disabled, ignoring audio chunk")
            return

        async with self.lock:
            queue = self.queues.get(session_id)
            if queue is None:
                queue = asyncio.Queue(maxsize=self.max_queue_size)
                self.queues[session_id] = queue
                self.tasks[session_id] = []
                await self._start_workers(session_id, queue)

        chunk = AudioChunk(
            base64_data=base64_data,
            mime_type=mime_type,
            speaker_id=speaker_id,
            speaker_name=speaker_name
        )

        try:
            queue.put_nowait(chunk)
        except asyncio.QueueFull:
            logger.warning("Queue is full for session %s. Dropping oldest chunk.", session_id)
            try:
                queue.get_nowait()
                queue.task_done()
                queue.put_nowait(chunk)
            except asyncio.QueueEmpty:
                logger.error("Failed to drop chunk from full queue for session %s", session_id)

    async def _requeue_chunk(self, session_id: str, chunk: AudioChunk) -> None:
        """å¤±æ•—ã—ãŸãƒãƒ£ãƒ³ã‚¯ã‚’å†åº¦ã‚­ãƒ¥ãƒ¼ã«ç©ã¿ç›´ã™"""
        async with self.lock:
            queue = self.queues.get(session_id)
            if queue is None:
                queue = asyncio.Queue(maxsize=self.max_queue_size)
                self.queues[session_id] = queue
                self.tasks[session_id] = []
                await self._start_workers(session_id, queue)

        try:
            queue.put_nowait(chunk)
        except asyncio.QueueFull:
            logger.warning(
                "Queue is full while requeueing for session %s. Dropping chunk after %d retries.",
                session_id,
                chunk.retries
            )

    async def _start_workers(self, session_id: str, queue: asyncio.Queue[AudioChunk]) -> None:
        """æŒ‡å®šã‚»ãƒƒã‚·ãƒ§ãƒ³ç”¨ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’èµ·å‹•"""
        for _ in range(self.concurrency):
            task = asyncio.create_task(self._worker_loop(session_id, queue))
            self.tasks[session_id].append(task)
            logger.info("Started transcription worker for %s", session_id)

    async def _worker_loop(self, session_id: str, queue: asyncio.Queue[AudioChunk]) -> None:
        """ã‚­ãƒ¥ãƒ¼ã‹ã‚‰éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å–ã‚Šå‡ºã—ã¦å‡¦ç†"""
        while True:
            try:
                chunk = await queue.get()
            except asyncio.CancelledError:
                break
            try:
                await self._process_chunk(session_id, chunk)
            except asyncio.CancelledError:
                raise
            except Exception as exc:
                logger.error(f"Transcription worker error for {session_id}: {exc}")
            finally:
                queue.task_done()

    def _get_session_lock(self, session_id: str) -> asyncio.Lock:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®ãƒ­ãƒƒã‚¯ã‚’å–å¾—"""
        if session_id not in self.session_locks:
            self.session_locks[session_id] = asyncio.Lock()
        return self.session_locks[session_id]

    async def _process_chunk(self, session_id: str, chunk: AudioChunk) -> None:
        """ãƒãƒ£ãƒ³ã‚¯ã‚’Whisperã«æŠ•ã’ã¦çµæœã‚’ä¿å­˜"""
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«ãƒ­ãƒƒã‚¯ã‚’å–å¾—ã—ã¦ã€ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚’å®Œå…¨ã«ã‚·ãƒªã‚¢ãƒ«åŒ–
        async with self._get_session_lock(session_id):
            logger.info("ğŸ”’ Lock acquired for %s, processing chunk", session_id)
            await self.__process_chunk_locked(session_id, chunk)
            logger.info("ğŸ”“ Lock released for %s", session_id)

    async def __process_chunk_locked(self, session_id: str, chunk: AudioChunk) -> None:
        """ãƒ­ãƒƒã‚¯å–å¾—å¾Œã®å®Ÿéš›ã®å‡¦ç†"""
        try:
            prompt = self._construct_prompt(session_id)
            logger.debug(f"ğŸ¤ Using prompt for {session_id}: {prompt}")
            
            transcription = await whisper_client.transcribe_audio_chunk(
                audio_base64=chunk.base64_data,
                mime_type=chunk.mime_type,
                prompt=prompt
            )
        except Exception as exc:
            chunk.retries += 1
            if chunk.retries <= chunk.max_retries:
                delay = chunk.backoff_delay()
                logger.warning(
                    "Transcription failed for %s (retry %d/%d): %s. Retrying in %.1fs",
                    session_id,
                    chunk.retries,
                    chunk.max_retries,
                    exc,
                    delay
                )
                await asyncio.sleep(delay)
                await self._requeue_chunk(session_id, chunk)
                return

            logger.error(
                "Transcription permanently failed for %s after %d retries: %s",
                session_id,
                chunk.max_retries,
                exc
            )
            return

        if not transcription:
            logger.debug("No transcription result for session %s (likely silence)", session_id)
            return

        normalized = transcription.strip()
        if not normalized:
            logger.debug("Empty transcription for %s", session_id)
            return

        prev_total = self._last_total_text.get(session_id)
        new_text = normalized
        
        logger.info("ğŸ” Processing transcription for %s:", session_id)
        logger.info("   Full text from Whisper: '%s'", normalized[:100])
        logger.info("   Previous cumulative: '%s'", (prev_total[:100] if prev_total else 'None'))
        
        if prev_total and len(normalized) > len(prev_total) and normalized.startswith(prev_total):
            new_text = normalized[len(prev_total):].lstrip()
            logger.info("   âœ‚ï¸ Extracted diff only: '%s'", new_text[:100])
        elif prev_total and normalized == prev_total:
            logger.info("   âŒ Identical to previous cumulative, skipping")
            return

        last_sent = self._last_sent_text.get(session_id)
        logger.info("   Last sent text: '%s'", (last_sent[:100] if last_sent else 'None'))
        
        if last_sent and last_sent == new_text.strip():
            logger.info("   âŒ Identical to last sent, skipping")
            self._last_total_text[session_id] = normalized
            return

        norm_key = self._normalize_text(new_text)
        logger.info("   Normalized key: '%s'", norm_key[:100])
        
        if not norm_key:
            logger.info("   âŒ Empty after normalization, skipping")
            self._last_total_text[session_id] = normalized
            return

        # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ­£è¦åŒ–å‰ï¼‰ã‚‚æ¯”è¼ƒ
        recent_list = self._recent_texts.setdefault(session_id, [])
        logger.info("   Recent keys count: %d", len(recent_list))
        
        if norm_key in recent_list:
            logger.info("   âŒ Found in recent 10 (normalized), skipping")
            self._last_total_text[session_id] = normalized
            return
        
        # å¿µã®ãŸã‚ã€å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚‚ç›´è¿‘3ä»¶ã¨å®Œå…¨ä¸€è‡´ãƒã‚§ãƒƒã‚¯
        for prev_key in recent_list[-3:]:
            if prev_key == norm_key:
                logger.info("   âŒ Exact match in recent 3, skipping")
                self._last_total_text[session_id] = normalized
                return

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        filtered_text = self._filter_transcription(new_text)
        if not filtered_text:
            logger.info(f"   ğŸ§¹ Filtered out text: '{new_text}'")
            self._last_total_text[session_id] = normalized
            return

        utterance = await self.session_manager.add_transcription_text(
            session_id=session_id,
            text=filtered_text,  # ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
            speaker_id=chunk.speaker_id,
            speaker_name=chunk.speaker_name
        )

        self._last_total_text[session_id] = normalized

        if not utterance:
            logger.debug("ğŸ”„ Duplicate or empty transcription skipped by session_manager for %s", session_id)
            return

        recent_list.append(norm_key)
        if len(recent_list) > 10:
            del recent_list[0]
        self._last_sent_text[session_id] = filtered_text.strip()
        
        logger.info("âœ… Added transcription for %s: '%s...' (%d chars)", 
                   session_id, filtered_text[:30], len(filtered_text))

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å†å–å¾—ã—ã¦AIã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å–å¾—
        session = self.session_manager.get_session(session_id)

        await self.broadcast(session_id, {
            'type': 'utterance_added',
            'data': utterance.model_dump()
        })

        # AIã‚«ã‚¦ãƒ³ã‚¿ãƒ¼æ›´æ–°ã‚’ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ
        if session:
            await self.broadcast(session_id, {
                'type': 'ai_counters_updated',
                'data': {
                    'pending_article_count': getattr(session, 'pending_ai_article_count', 0),
                    'pending_question_count': getattr(session, 'pending_ai_question_count', 0)
                }
            })

        if self.on_transcription_appended:
            logger.info("ğŸ”” Triggering AI processing callback for %s", session_id)
            # ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¦ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ 
            task = asyncio.create_task(self._notify_transcription_appended(session_id))
            # ã‚¿ã‚¹ã‚¯ã®ã‚¨ãƒ©ãƒ¼ã‚’ç¢ºå®Ÿã«ã‚­ãƒ£ãƒƒãƒ
            task.add_done_callback(lambda t: self._handle_task_exception(t, session_id))
        else:
            logger.warning("âš ï¸ No AI processing callback registered!")

    def _handle_task_exception(self, task: asyncio.Task, session_id: str) -> None:
        """éåŒæœŸã‚¿ã‚¹ã‚¯ã®ä¾‹å¤–ã‚’å‡¦ç†"""
        try:
            task.result()
        except Exception as exc:
            logger.error(
                "âŒâŒâŒ CRITICAL: Unhandled exception in AI processing task for %s: %s",
                session_id,
                exc,
                exc_info=True
            )

    async def _notify_transcription_appended(self, session_id: str) -> None:
        """æ–‡å­—èµ·ã“ã—è¿½è¨˜å¾Œã®ãƒ•ãƒƒã‚¯ã‚’éåŒæœŸã§å®Ÿè¡Œ"""
        if not self.on_transcription_appended:
            logger.warning("âš ï¸ on_transcription_appended is None in _notify_transcription_appended")
            return

        try:
            logger.info("ğŸ¯ Calling AI processing callback for %s", session_id)
            await self.on_transcription_appended(session_id)
            logger.info("âœ… AI processing callback completed for %s", session_id)
        except Exception as exc:
            logger.error(
                "âŒ Error in on_transcription_appended callback for %s: %s",
                session_id,
                exc,
                exc_info=True
            )
            # ã‚¨ãƒ©ãƒ¼ã‚’å†ã‚¹ãƒ­ãƒ¼ã—ã¦ã€add_done_callbackã§ã‚‚ã‚­ãƒ£ãƒƒãƒã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
            raise

    @property
    def enabled(self) -> bool:
        return whisper_client.enabled

    async def stop_for_session(self, session_id: str) -> None:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢ã—ã€ã‚­ãƒ¥ãƒ¼ã‚’ç©ºã«ã™ã‚‹"""
        async with self.lock:
            tasks = self.tasks.pop(session_id, [])
            for task in tasks:
                task.cancel()
            queue = self.queues.pop(session_id, None)
            self._recent_texts.pop(session_id, None)
            self._last_total_text.pop(session_id, None)
            self._last_sent_text.pop(session_id, None)
            self.session_locks.pop(session_id, None)

        for task in tasks:
            try:
                await task
            except asyncio.CancelledError:
                pass
        if queue:
            while not queue.empty():
                queue.get_nowait()
                queue.task_done()

        logger.info("Stopped transcription workers for %s", session_id)

    async def shutdown(self) -> None:
        """å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢"""
        async with self.lock:
            session_ids = list(self.tasks.keys())

        for session_id in session_ids:
            await self.stop_for_session(session_id)

