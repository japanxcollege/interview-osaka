
import logging
from typing import Optional
from gemini_client import gemini_client
from anthropic_client import anthropic_client
from openai_client import openai_client
from style_manager import style_manager

logger = logging.getLogger(__name__)

class AIEditorService:
    def __init__(self):
        pass

    async def edit_text(
        self,
        # Instructions for editing text
        instruction: str,
        selected_text: Optional[str] = None,
        context: Optional[str] = None,
        model_provider: str = "gemini",
        chat_history: list = []
    ) -> Optional[str]:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆç·¨é›†/ç”Ÿæˆã‚’å®Ÿè¡Œ
        """
        system_prompt = """ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼ãƒ»ç·¨é›†è€…ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆã€ç·¨é›†ã€ã¾ãŸã¯æ”¹å–„ã—ã¦ãã ã•ã„ã€‚
ã€Œè¦ç´„ã€ã‚„ã€Œç›¸è«‡ã€ã®å ´åˆã¯ã€ä¼šè©±å½¢å¼ã§ç­”ãˆã¦ãã ã•ã„ã€‚
ã€Œç·¨é›†ã€ã‚„ã€Œæ›¸ãç›´ã—ã€ã®å ´åˆã¯ã€çµæœã®Markdownãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""

        user_content = []
        
        # Add chat history context if available
        if chat_history:
            history_text = "\n".join([f"{msg.get('role', 'unknown')}: {msg.get('content', '')}" for msg in chat_history])
            user_content.append(f"# ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´\n{history_text}\n")

        if context:
            user_content.append(f"# æ–‡è„ˆãƒ»èƒŒæ™¯\n{context}\n")
        
        if selected_text:
            user_content.append(f"# å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ\n{selected_text}\n")
            
        user_content.append(f"# ä»Šå›ã®æŒ‡ç¤º\n{instruction}")
        
        user_prompt = "\n".join(user_content)

        if model_provider == "claude":
            if not anthropic_client.enabled:
                raise Exception("Claude API is not enabled. Check ANTHROPIC_API_KEY.")
            return await anthropic_client.generate_text(system_prompt, user_prompt)
        
        else: # Default to Gemini
            if not gemini_client.enabled:
                error_msg = "Gemini API is not enabled. Check GEMINI_API_KEY."
                logger.error(error_msg)
                raise Exception(error_msg)
            
            logger.info(f"ğŸ¤– Generating text with Gemini. System prompt len: {len(system_prompt)}, User prompt len: {len(user_prompt)}")
            result = await gemini_client.generate_text(system_prompt, user_prompt)
            if not result:
                logger.warning("âš ï¸ Gemini returned None for edit_text")
            return result

    async def generate_draft_from_transcript(
        self,
        transcript_text: str,
        style: str,
        key_points: Optional[list[str]] = None,
        context: Optional[str] = None,
        model_provider: str = "gemini"
    ) -> Optional[str]:
        """
        æ–‡å­—èµ·ã“ã— + ã‚¹ã‚¿ã‚¤ãƒ« + ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ ã‹ã‚‰è¨˜äº‹ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ç”Ÿæˆ
        """
        # Dynamic style lookup
        prompt_style = style_manager.get_by_id(style)
        style_instruction = prompt_style.instruction if prompt_style else "Q&Aå½¢å¼ï¼ˆå¯¾è«‡å½¢å¼ï¼‰ã§ã€è³ªå•ã¨å›ç­”ãŒæ˜ç¢ºã«åˆ†ã‹ã‚‹ã‚ˆã†ã«æ§‹æˆã—ã¦ãã ã•ã„ã€‚"
        
        key_points_text = ""
        if key_points:
            key_points_list = "\n".join([f"- {kp}" for kp in key_points])
            key_points_text = f"\n# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé‡è¦–ã™ã‚‹ãƒã‚¤ãƒ³ãƒˆï¼ˆå¿…ãšè¨˜äº‹ã«åæ˜ ã—ã¦ãã ã•ã„ï¼‰\n{key_points_list}\n"

        system_prompt = """ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
æ¸¡ã•ã‚ŒãŸã€Œæ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã€ã‚’å…ƒã«ã€é«˜å“è³ªãªè¨˜äº‹ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
        
        context_text = ""
        if context:
            context_text = f"\n# è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ»èƒŒæ™¯æƒ…å ±ï¼ˆå‚è€ƒãƒ¡ãƒ¢ï¼‰\n{context}\n"

        user_prompt = f"""
# æŒ‡ç¤º
{style_instruction}
{context_text}
{key_points_text}

# æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ
{transcript_text}

# å‡ºåŠ›å½¢å¼
Markdownå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ#ï¼‰ã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„ã€‚
"""

        if model_provider == "claude":
             if anthropic_client.enabled:
                 return await anthropic_client.generate_text(system_prompt, user_prompt)
        
        # Default Gemini
        if gemini_client.enabled:
             return await gemini_client.generate_text(system_prompt, user_prompt)
             
    async def generate_interviewer_response(
        self,
        transcript_text: str,
        context: Optional[str] = None,
        chat_history: list = [],
        model_provider: str = "gemini",
        ai_mode: str = "empath",
        instruction: Optional[str] = None
    ) -> Optional[str]:
        """
        ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã®é€²è¡Œå½¹ã¨ã—ã¦ã€æ¬¡ã®è³ªå•ã‚„åå¿œã‚’ç”Ÿæˆã™ã‚‹
        ãƒ¢ãƒ¼ãƒ‰: empath (å…±æ„Ÿ/æ·±æ˜ã‚Š), friction (é•å’Œæ„Ÿ/çŸ›ç›¾æŒ‡æ‘˜), rephrase (è¨€ã„æ›ãˆ/æ§‹é€ åŒ–)
        """
        
        mode_instruction = ""
        if ai_mode == "friction":
            mode_instruction = """
# ãƒ¢ãƒ¼ãƒ‰: é•å’Œæ„Ÿãƒ»çŸ›ç›¾ã®æŒ‡æ‘˜ (Friction)
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è©±ã®ä¸­ã«æ½œã‚€ã€ŒçŸ›ç›¾ã€ã‚„ã€Œæ›–æ˜§ãªç‚¹ã€ã€ã€Œå»ºå‰ã¨æœ¬éŸ³ã®ã‚ºãƒ¬ã€ã‚’å„ªã—ãæŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚
- "ã‚ãˆã¦" å°‘ã—æ‰¹åˆ¤çš„ãªè¦–ç‚¹ã‚„ã€ç•°ãªã‚‹è¦–ç‚¹ã‚’æŠ•ã’ã‹ã‘ã¦ãã ã•ã„ã€‚
- ç›®çš„ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã€Œãƒãƒƒã€ã¨ã•ã›ã‚‹ã“ã¨ã§ã™ã€‚æ”»æ’ƒçš„ã«ãªã‚‰ãªã„ã‚ˆã†æ³¨æ„ã—ã¦ãã ã•ã„ã€‚
"""
        elif ai_mode == "rephrase":
            mode_instruction = """
# ãƒ¢ãƒ¼ãƒ‰: è¨€ã„æ›ãˆãƒ»æ§‹é€ åŒ– (Rephrase)
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è©±ã‚’æ•´ç†ãƒ»è¦ç´„ã—ã€ã€Œã¤ã¾ã‚Šã€ã“ã†ã„ã†ã“ã¨ã§ã™ã‹ï¼Ÿã€ã¨ç¢ºèªã—ã¦ãã ã•ã„ã€‚
- è©±ã®æ§‹é€ ï¼ˆåŸå› ã¨çµæœã€å¯¾ç«‹è»¸ãªã©ï¼‰ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
- æŠ½è±¡çš„ãªè©±ã‚’å…·ä½“åŒ–ã—ãŸã‚Šã€å…·ä½“çš„ãªè©±ã‚’æŠ½è±¡åŒ–ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚
"""
        else: # empath (default)
            mode_instruction = """
# ãƒ¢ãƒ¼ãƒ‰: å…±æ„Ÿãƒ»æ·±æ˜ã‚Š (Empathy)
- ç›¸æ‰‹ã®æ„Ÿæƒ…ã«å¯„ã‚Šæ·»ã„ã€å…±æ„Ÿã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚
- ã€Œãªãœãã†æ„Ÿã˜ãŸã®ã§ã™ã‹ï¼Ÿã€ã€Œå…·ä½“çš„ã«ã¯ï¼Ÿã€ã¨å„ªã—ãæ·±æ˜ã‚Šã—ã¦ãã ã•ã„ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå®‰å¿ƒã—ã¦è©±ã›ã‚‹é›°å›²æ°—ã‚’ä½œã£ã¦ãã ã•ã„ã€‚è‚¯å®šçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚
"""

        system_prompt = f"""ã‚ãªãŸã¯ãƒ—ãƒ­ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ã§ã™ã€‚
æ¸¡ã•ã‚ŒãŸæ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã¨ã“ã‚Œã¾ã§ã®ä¼šè©±ã‚’å…ƒã«ã€æ¬¡ã«å°‹ã­ã‚‹ã¹ãè³ªå•ã€ã¾ãŸã¯è©±ã‚’å¼•ãå‡ºã™ãŸã‚ã®åå¿œã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{mode_instruction}

# åŸºæœ¬çš„ãªæŒ¯èˆã„
- è¦ªã—ã¿ã‚„ã™ãã€ã‹ã¤ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªãƒˆãƒ¼ãƒ³ã‚’ä¿ã£ã¦ãã ã•ã„ã€‚
- éŸ³å£°ã§èª­ã¿ä¸Šã’ã‚‹ã“ã¨ã‚’å‰æã«ã€è‡ªç„¶ãªè©±ã—è¨€è‘‰ï¼ˆã§ã™ãƒ»ã¾ã™èª¿ï¼‰ã§çŸ­ã‚ã«ç­”ãˆã¦ãã ã•ã„ã€‚
- ä¸€åº¦ã«å¤šãã®è³ªå•ã‚’ã›ãšã€1ã¤ãšã¤æ·±æ˜ã‚Šã—ã¦ãã ã•ã„ã€‚
- æ±ºã—ã¦ã€Œçµè«–ã€ã‚’æŠ¼ã—ä»˜ã‘ãªã„ã§ãã ã•ã„ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ°—ã¥ãã‚’ä¸ãˆã‚‹ã“ã¨ãŒç›®çš„ã§ã™ã€‚
"""
        
        user_content = []
        
        if context:
            user_content.append(f"# ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã®ç›®çš„ãƒ»èƒŒæ™¯\n{context}\n")
            
        if chat_history:
            history_text = "\n".join([f"{msg.get('role', 'unknown')}: {msg.get('content', '')}" for msg in chat_history])
            user_content.append(f"# ã“ã‚Œã¾ã§ã®AIã¨ã®ã‚„ã‚Šå–ã‚Š\n{history_text}\n")
            
        if transcript_text:
            user_content.append(f"# ç¾åœ¨ã®æ–‡å­—èµ·ã“ã—ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ãªã©ï¼‰\n{transcript_text}\n")
            
        if instruction:
            user_content.append(f"# å…·ä½“çš„ãªæŒ‡ç¤ºï¼ˆã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ãªã©ï¼‰\n{instruction}\n")

        user_content.append("æ¬¡ã«ã€ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ã¨ã—ã¦ã©ã®ã‚ˆã†ãªç™ºè¨€ã‚’ã™ã¹ãã‹ã€ç™ºè¨€å†…å®¹ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚")
        
        user_prompt = "\n".join(user_content)

        if model_provider == "claude":
            if anthropic_client.enabled:
                return await anthropic_client.generate_text(system_prompt, user_prompt)
            else:
                logger.warning("Claude requested but anthropic_client is not enabled")
        
        if model_provider == "openai":
            if openai_client.enabled:
                return await openai_client.generate_text(system_prompt, user_prompt)
            else:
                logger.warning("OpenAI requested but openai_client is not enabled")
        
        # Default Gemini
        if gemini_client.enabled:
            result = await gemini_client.generate_text(system_prompt, user_prompt)
            if not result:
                logger.warning("Gemini returned None for interviewer response")
            return result
        else:
            logger.warning("Gemini API not enabled for interviewer response")
            
        return None


ai_editor = AIEditorService()
